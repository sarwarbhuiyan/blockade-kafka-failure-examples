containers:
  zk1:
    image: zookeeper:3.4.9
    hostname: zk1
    container_name: zk1
    environment: { "ZOO_MY_ID": 1, "ZOO_PORT": 2181, "ZOO_SERVERS": "server.1=0.0.0.0:2888:3888" }
    # uncomment if you want the data to survive resets of the cluster
    #volumes: { "./volumes/zookeeper/01/data/data": "/data", "./volumes/zookeeper/01/datalog": "/datalog" }
    expose: [2181]

  kafka1:
    image: jackvanlightly/kafka-cp-with-http-reporter:5.2.1-0.3.2
    hostname: kafka1
    container_name: kafka1
    expose: [9092]
    environment: { 
      "KAFKA_ADVERTISED_LISTENERS": "PLAINTEXT://kafka1:9092,PLAINTEXT_IB://kafka1:29092", 
      "KAFKA_LISTENER_SECURITY_PROTOCOL_MAP": "PLAINTEXT:PLAINTEXT,PLAINTEXT_IB:PLAINTEXT", 
      "KAFKA_INTER_BROKER_LISTENER_NAME": "PLAINTEXT_IB",
      "KAFKA_ZOOKEEPER_CONNECT": "zk1:2181", 
      "KAFKA_BROKER_ID": 1, 
      "KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE": "false",
      "KAFKA_LOG4J_LOGGERS": "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO",
      "KAFKA_METRIC_REPORTERS": "cloudkarafka.kafka_http_reporter" }
    # uncomment if you want the data to survive resets of the cluster
    #volumes: { "./volumes/kafka/01/data": "/var/lib/kafka/data" }
    start_delay: 5
    
  kafka2:
    image: jackvanlightly/kafka-cp-with-http-reporter:5.2.1-0.3.2
    hostname: kafka2
    container_name: kafka2
    expose: [9092]
    environment: { 
      "KAFKA_ADVERTISED_LISTENERS": "PLAINTEXT://kafka2:9092,PLAINTEXT_IB://kafka2:29092",
      "KAFKA_LISTENER_SECURITY_PROTOCOL_MAP": "PLAINTEXT:PLAINTEXT,PLAINTEXT_IB:PLAINTEXT", 
      "KAFKA_INTER_BROKER_LISTENER_NAME": "PLAINTEXT_IB",
      "KAFKA_ZOOKEEPER_CONNECT": "zk1:2181",
      "KAFKA_BROKER_ID": 2,
      "KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE": "false",
      "KAFKA_LOG4J_LOGGERS": "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO",
      "KAFKA_METRIC_REPORTERS": "cloudkarafka.kafka_http_reporter" }
    # uncomment if you want the data to survive resets of the cluster
    #volumes: { "./volumes/kafka/02/data": "/var/lib/kafka/data" }
    start_delay: 1

  kafka3:
    image: jackvanlightly/kafka-cp-with-http-reporter:5.2.1-0.3.2
    hostname: kafka3
    container_name: kafka3
    expose: [9092]
    environment: { 
      "KAFKA_ADVERTISED_LISTENERS": "PLAINTEXT://kafka3:9092,PLAINTEXT_IB://kafka3:29092",
      "KAFKA_LISTENER_SECURITY_PROTOCOL_MAP": "PLAINTEXT:PLAINTEXT,PLAINTEXT_IB:PLAINTEXT", 
      "KAFKA_INTER_BROKER_LISTENER_NAME": "PLAINTEXT_IB",
      "KAFKA_ZOOKEEPER_CONNECT": "zk1:2181",
      "KAFKA_BROKER_ID": 3,
      "KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE": "false",
      "KAFKA_LOG4J_LOGGERS": "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO",
      "KAFKA_METRIC_REPORTERS": "cloudkarafka.kafka_http_reporter" }
    # uncomment if you want the data to survive resets of the cluster
    #volumes: { "./volumes/kafka/03/data": "/var/lib/kafka/data" }
    start_delay: 1

  manager:
    image: jackvanlightly/cloudkarafka-manager:latest
    hostname: manager
    container_name: manager
    environment: {
      "AUTH_MODE": "none-with-write",
      "ZOOKEEPER": "zk1:2181"
    }
    expose: [8080]
    

network:
  driver: udn
  flaky: 5%
  slow: 100ms 50ms 25% distribution normal